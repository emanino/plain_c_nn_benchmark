// This file is computer-generated by onnx2c 
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 2.0.1
// ONNX IR version: 14
// Model documentation: 
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
#define MAX(X,Y) ( X > Y ? X : Y)
#define MIN(X,Y) ( X < Y ? X : Y)
#define CLIP(X,L) ( MAX(MIN(X,L), -L) )

static const float tensor__1_Constant_output_0[4][4] = 
{
  {0.31936630606651306152f, 0.74668097496032714844f, -0.84259569644927978516f, 0.24554631114006042480f},
  {0.13787679374217987061f, 0.19928121566772460938f, 0.21798191964626312256f, 0.12787388265132904053f},
  {0.83516061305999755859f, -0.10287145525217056274f, -0.021308772265911102295f, -0.68423432111740112305f},
  {-0.11210761964321136475f, -0.46745365858078002930f, -0.53386807441711425781f, -0.18181385099887847900f}
};
static const float tensor__1_Constant_1_output_0[4] = 
{0.28033089637756347656f, 0.39092287421226501465f, 0.33171588182449340820f, 0.40277084708213806152f};
static const float tensor__1_Constant_2_output_0[4][4] = 
{
  {0.43055444955825805664f, 1.0066397190093994141f, -1.1359474658966064453f, 0.33103385567665100098f},
  {1.0174783468246459961f, 1.4706195592880249023f, 1.6086236238479614258f, 0.94366061687469482422f},
  {1.2401516437530517578f, -0.15275649726390838623f, -0.031641948968172073364f, -1.0160373449325561523f},
  {-0.16151103377342224121f, -0.67345041036605834961f, -0.76913225650787353516f, -0.26193529367446899414f}
};
static const float tensor__2_Constant_output_0[4][4] = 
{
  {0.24955554306507110596f, 0.26488065719604492188f, 0.11186323314905166626f, -0.082774937152862548828f},
  {0.10204764455556869507f, -0.041352130472660064697f, -0.19660033285617828369f, -0.42108407616615295410f},
  {-0.40751013159751892090f, 0.12845632433891296387f, 0.47575941681861877441f, 0.57491093873977661133f},
  {-0.61466467380523681641f, -1.5005122423171997070f, 0.66851800680160522461f, -0.18509793281555175781f}
};
static const float tensor__2_Constant_1_output_0[4] = 
{0.56154775619506835938f, 0.20235647261142730713f, 0.38030025362968444824f, 0.13251489400863647461f};
static const float tensor__2_Constant_2_output_0[4][4] = 
{
  {1.3005535602569580078f, 1.3804200887680053711f, 0.58297288417816162109f, -0.43137985467910766602f},
  {0.21936568617820739746f, -0.088892184197902679443f, -0.42261990904808044434f, -0.90517908334732055664f},
  {-0.74000042676925659180f, 0.23326472938060760498f, 0.86393481492996215820f, 1.0439847707748413086f},
  {-0.21768797934055328369f, -0.53141736984252929688f, 0.23676052689552307129f, -0.065553784370422363281f}
};
static const float tensor__3_Constant_output_0[1][4] = 
{
  {-0.047150183469057083130f, -0.86632072925567626953f, 0.00052731094183400273323f, -0.49725759029388427734f}
};
static const float tensor__3_Constant_1_output_0[1] = 
{-0.25362345576286315918f};
union tensor_union_0 {
float tensor__1_Gemm_output_0[1][4];
float tensor__1_MatMul_output_0[1][4];
float tensor__2_Gemm_output_0[1][4];
float tensor__2_MatMul_output_0[1][4];
};
static union tensor_union_0 tu0;

union tensor_union_1 {
float tensor__1_activation_Relu_output_0[1][4];
float tensor__1_Sub_output_0[1][4];
};
static union tensor_union_1 tu1;

union tensor_union_2 {
float tensor__2_activation_Relu_output_0[1][4];
float tensor__2_Sub_output_0[1][4];
};
static union tensor_union_2 tu2;


static inline void node__1_Gemm( const float tensor_onnx__Pad_0[1][4], const float tensor__1_Constant_output_0[4][4], const float tensor__1_Constant_1_output_0[4], float tensor__1_Gemm_output_0[1][4] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 4;
	const int N = 4;
	float (*A)[4]  = (float(*)[4])tensor_onnx__Pad_0;
	float (*Y)[4]  = (float(*)[4])tensor__1_Gemm_output_0;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[4]  = (float(*)[4])tensor__1_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__1_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}

static inline void node__1_activation_Relu( const float tensor__1_Gemm_output_0[1][4], float tensor__1_activation_Relu_output_0[1][4] )
{
	/*Relu*/
	float *X = (float*)tensor__1_Gemm_output_0;
	float *Y = (float*)tensor__1_activation_Relu_output_0;
	for( uint32_t i=0; i<4; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;

}

static inline void node__1_MatMul( const float A[1][4], const float B[4][4], float Y[1][4] )
{
	/* MatMul */
	for( uint32_t r=0; r<1; r++ )
		for( uint32_t c=0; c<4; c++ ) {
			Y[r][c] = 0;
			for( uint32_t i=0; i<4; i++ )
				Y[r][c] += A[r][i] * B[i][c];
		}
}

static inline void node__1_Sub( const float tensor_onnx__Pad_0[1][4], const float tensor__1_MatMul_output_0[1][4], float tensor__1_Sub_output_0[1][4] )
{
	/* Sub
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<1; i0++) {
	for (unsigned i1=0; i1<4; i1++) {
		tensor__1_Sub_output_0[i0][i1] = tensor_onnx__Pad_0[0][i1]-tensor__1_MatMul_output_0[0][i1];;
	}
	}
}

static inline void node__2_Gemm( const float tensor__1_Sub_output_0[1][4], const float tensor__2_Constant_output_0[4][4], const float tensor__2_Constant_1_output_0[4], float tensor__2_Gemm_output_0[1][4] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 4;
	const int N = 4;
	float (*A)[4]  = (float(*)[4])tensor__1_Sub_output_0;
	float (*Y)[4]  = (float(*)[4])tensor__2_Gemm_output_0;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[4]  = (float(*)[4])tensor__2_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__2_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}

static inline void node__2_activation_Relu( const float tensor__2_Gemm_output_0[1][4], float tensor__2_activation_Relu_output_0[1][4] )
{
	/*Relu*/
	float *X = (float*)tensor__2_Gemm_output_0;
	float *Y = (float*)tensor__2_activation_Relu_output_0;
	for( uint32_t i=0; i<4; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;

}

static inline void node__2_MatMul( const float A[1][4], const float B[4][4], float Y[1][4] )
{
	/* MatMul */
	for( uint32_t r=0; r<1; r++ )
		for( uint32_t c=0; c<4; c++ ) {
			Y[r][c] = 0;
			for( uint32_t i=0; i<4; i++ )
				Y[r][c] += A[r][i] * B[i][c];
		}
}

static inline void node__2_Sub( const float tensor__1_Sub_output_0[1][4], const float tensor__2_MatMul_output_0[1][4], float tensor__2_Sub_output_0[1][4] )
{
	/* Sub
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<1; i0++) {
	for (unsigned i1=0; i1<4; i1++) {
		tensor__2_Sub_output_0[i0][i1] = tensor__1_Sub_output_0[0][i1]-tensor__2_MatMul_output_0[0][i1];;
	}
	}
}

static inline void node__3_Gemm( const float tensor__2_Sub_output_0[1][4], const float tensor__3_Constant_output_0[1][4], const float tensor__3_Constant_1_output_0[1], float tensor_43[1][1] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 4;
	const int N = 1;
	float (*A)[4]  = (float(*)[4])tensor__2_Sub_output_0;
	float (*Y)[1]  = (float(*)[1])tensor_43;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[1]  = (float(*)[1])tensor__3_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__3_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][0] * beta;
			Y[r][c] = tmp;
	}
}


void entry(const float tensor_onnx__Pad_0[1][4], float tensor_43[1][1]) {
	node__1_Gemm( tensor_onnx__Pad_0, tensor__1_Constant_output_0, tensor__1_Constant_1_output_0, tu0.tensor__1_Gemm_output_0);
	node__1_activation_Relu( tu0.tensor__1_Gemm_output_0, tu1.tensor__1_activation_Relu_output_0);
	node__1_MatMul( tu1.tensor__1_activation_Relu_output_0, tensor__1_Constant_2_output_0, tu0.tensor__1_MatMul_output_0);
	node__1_Sub( tensor_onnx__Pad_0, tu0.tensor__1_MatMul_output_0, tu1.tensor__1_Sub_output_0);
	node__2_Gemm( tu1.tensor__1_Sub_output_0, tensor__2_Constant_output_0, tensor__2_Constant_1_output_0, tu0.tensor__2_Gemm_output_0);
	node__2_activation_Relu( tu0.tensor__2_Gemm_output_0, tu2.tensor__2_activation_Relu_output_0);
	node__2_MatMul( tu2.tensor__2_activation_Relu_output_0, tensor__2_Constant_2_output_0, tu0.tensor__2_MatMul_output_0);
	node__2_Sub( tu1.tensor__1_Sub_output_0, tu0.tensor__2_MatMul_output_0, tu2.tensor__2_Sub_output_0);
	node__3_Gemm( tu2.tensor__2_Sub_output_0, tensor__3_Constant_output_0, tensor__3_Constant_1_output_0, tensor_43);
}
