// This file is computer-generated by onnx2c 
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 2.0.1
// ONNX IR version: 14
// Model documentation: 
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
#define MAX(X,Y) ( X > Y ? X : Y)
#define MIN(X,Y) ( X < Y ? X : Y)
#define CLIP(X,L) ( MAX(MIN(X,L), -L) )

static const float tensor__0_Constant_8_output_0[1] = 
{0.0000000000000000000f};
static const float tensor__1_Constant_output_0[8][8] = 
{
  {0.75162446498870849609f, 0.11617416888475418091f, -0.40057268738746643066f, 0.10998067259788513184f, -0.36240333318710327148f, 0.0095818946138024330139f, -0.23890109360218048096f, 0.036476753652095794678f},
  {-0.22390182316303253174f, 0.042328290641307830811f, -0.21391096711158752441f, -0.52809518575668334961f, -0.22705483436584472656f, 0.11383725702762603760f, -0.24475666880607604980f, -0.19848600029945373535f},
  {-0.31124156713485717773f, -0.0030064117163419723511f, -0.34413436055183410645f, 0.29753836989402770996f, -0.25320303440093994141f, -0.55380010604858398438f, 0.072174705564975738525f, -0.17893627285957336426f},
  {0.010761383920907974243f, -0.76384764909744262695f, 0.095196515321731567383f, -0.010216142982244491577f, -0.42489916086196899414f, -0.65880811214447021484f, -0.019024549052119255066f, -0.12518580257892608643f},
  {0.23748095333576202393f, 0.30665361881256103516f, 0.022767281159758567810f, 0.57351636886596679688f, -0.19823713600635528564f, -0.042896609753370285034f, 0.36292552947998046875f, -0.34568014740943908691f},
  {0.14620041847229003906f, -0.00036121575976721942425f, -0.27193674445152282715f, -0.18178813159465789795f, -0.24092881381511688232f, 0.047957051545381546021f, 0.39333167672157287598f, 0.31609156727790832520f},
  {0.25181326270103454590f, -0.24037991464138031006f, -0.012337330728769302368f, 0.34670019149780273438f, 0.064490988850593566895f, -0.044654238969087600708f, 0.039546169340610504150f, 0.23196570575237274170f},
  {0.10836473107337951660f, -0.10644072294235229492f, -0.099701464176177978516f, -0.10537441074848175049f, 0.23253600299358367920f, -0.088608041405677795410f, 0.13815458118915557861f, -0.17549227178096771240f}
};
static const float tensor__1_Constant_1_output_0[8] = 
{0.11623781919479370117f, 0.49419355392456054688f, -0.72771972417831420898f, -0.89252728223800659180f, 0.49544447660446166992f, -0.038089368492364883423f, 0.11522281914949417114f, -0.089491270482540130615f};
static const float tensor__1_Constant_2_output_0[8][8] = 
{
  {0.45177397131919860840f, 0.069828040897846221924f, -0.24076959490776062012f, 0.066105358302593231201f, -0.21782739460468292236f, 0.0057593262754380702972f, -0.14359471201896667480f, 0.021924842149019241333f},
  {-0.43973809480667114258f, 0.083131805062294006348f, -0.42011630535125732422f, -1.0371669530868530273f, -0.44593054056167602539f, 0.22357378900051116943f, -0.48069655895233154297f, -0.38982200622558593750f},
  {-0.53938943147659301758f, -0.0052101868204772472382f, -0.59639346599578857422f, 0.51564145088195800781f, -0.43880721926689147949f, -0.95974946022033691406f, 0.12508057057857513428f, -0.31010106205940246582f},
  {0.010194314643740653992f, -0.72359681129455566406f, 0.090180151164531707764f, -0.0096778050065040588379f, -0.40250915288925170898f, -0.62409234046936035156f, -0.018022052943706512451f, -0.11858915537595748901f},
  {0.15117083489894866943f, 0.19520337879657745361f, 0.014492737129330635071f, 0.36507749557495117188f, -0.12618979811668395996f, -0.027306258678436279297f, 0.23102381825447082520f, -0.22004610300064086914f},
  {0.61483395099639892578f, -0.0015190634876489639282f, -1.1436078548431396484f, -0.76449519395828247070f, -1.0132064819335937500f, 0.20167948305606842041f, 1.6541243791580200195f, 1.3292973041534423828f},
  {0.30842277407646179199f, -0.29441910982131958008f, -0.015110854990780353546f, 0.42464098334312438965f, 0.078989043831825256348f, -0.054692845791578292847f, 0.048436444252729415894f, 0.28411334753036499023f},
  {1.0272917747497558594f, -1.0090522766113281250f, -0.94516450166702270508f, -0.99894374608993530273f, 2.2044286727905273438f, -0.83999943733215332031f, 1.3096979856491088867f, -1.6636573076248168945f}
};
static const float tensor__2_Constant_output_0[8][8] = 
{
  {-0.47079703211784362793f, -0.28995513916015625000f, 0.25896364450454711914f, 0.0049692620523273944855f, 0.088740706443786621094f, 0.24298353493213653564f, -0.67860668897628784180f, -0.41340616345405578613f},
  {0.17364297807216644287f, 0.43202847242355346680f, 0.25435772538185119629f, -0.50163137912750244141f, -0.34971478581428527832f, -0.37817785143852233887f, -0.11880844831466674805f, -0.45257890224456787109f},
  {0.37170714139938354492f, -0.30676203966140747070f, -0.48982438445091247559f, -0.49678716063499450684f, 0.17498852312564849854f, 0.0027374117635190486908f, 0.10090960562229156494f, -0.74765652418136596680f},
  {0.46694192290306091309f, -0.17279221117496490479f, -0.063455440104007720947f, 0.47496971487998962402f, -0.37160325050354003906f, -0.47952094674110412598f, 0.50609469413757324219f, 0.0083183767274022102356f},
  {0.45483443140983581543f, 0.25856542587280273438f, -0.15572841465473175049f, 0.28544673323631286621f, 0.45487275719642639160f, -0.29888504743576049805f, -0.56933605670928955078f, 0.060963593423366546631f},
  {-0.0055014621466398239136f, -0.32430624961853027344f, -0.38917645812034606934f, 0.055428493767976760864f, -0.47452574968338012695f, 0.31952998042106628418f, -0.077933706343173980713f, 0.15911182761192321777f},
  {0.40686669945716857910f, 0.15342290699481964111f, 0.22048959136009216309f, -0.027628237381577491760f, -0.061941035091876983643f, 0.41043624281883239746f, 0.071747206151485443115f, 0.14301458001136779785f},
  {-0.39010858535766601562f, 0.34365093708038330078f, -0.28568705916404724121f, 0.25917652249336242676f, 0.087690405547618865967f, -0.11775089800357818604f, 0.15413500368595123291f, -0.27889072895050048828f}
};
static const float tensor__2_Constant_1_output_0[8] = 
{-0.057593014091253280640f, 0.93225365877151489258f, 0.16690053045749664307f, 0.40462917089462280273f, -0.036327403038740158081f, 0.43557780981063842773f, -0.058803845196962356567f, -0.27984276413917541504f};
static const float tensor__2_Constant_2_output_0[8][8] = 
{
  {-0.21530374884605407715f, -0.13260157406330108643f, 0.11842862516641616821f, 0.0022725306916981935501f, 0.040582682937383651733f, 0.11112064123153686523f, -0.31033876538276672363f, -0.18905790150165557861f},
  {0.24922685325145721436f, 0.62008321285247802734f, 0.36507537961006164551f, -0.71998310089111328125f, -0.50193977355957031250f, -0.54279232025146484375f, -0.17052376270294189453f, -0.64957886934280395508f},
  {0.30663749575614929199f, -0.25306144356727600098f, -0.40407758951187133789f, -0.40982148051261901855f, 0.14435569941997528076f, 0.0022582109086215496063f, 0.083244748413562774658f, -0.61677461862564086914f},
  {0.72560763359069824219f, -0.26851165294647216797f, -0.098607018589973449707f, 0.73808246850967407227f, -0.57745540142059326172f, -0.74515485763549804688f, 0.78644931316375732422f, 0.012926398776471614838f},
  {0.85151416063308715820f, 0.48407092690467834473f, -0.29154554009437561035f, 0.53439652919769287109f, 0.85158592462539672852f, -0.55955493450164794922f, -1.0658773183822631836f, 0.11413244158029556274f},
  {-0.0033658978063613176346f, -0.19841665029525756836f, -0.23810547590255737305f, 0.033912193030118942261f, -0.29032376408576965332f, 0.19549444317817687988f, -0.047681305557489395142f, 0.097347602248191833496f},
  {1.1663243770599365234f, 0.43980222940444946289f, 0.63205564022064208984f, -0.079199127852916717529f, -0.17756022512912750244f, 1.1765568256378173828f, 0.20567059516906738281f, 0.40996569395065307617f},
  {-0.76811194419860839844f, 0.67663824558258056641f, -0.56250911951065063477f, 0.51031070947647094727f, 0.17265973985195159912f, -0.23184794187545776367f, 0.30348712205886840820f, -0.54912734031677246094f}
};
static const float tensor__3_Constant_output_0[1][8] = 
{
  {-0.32836291193962097168f, 0.29350760579109191895f, 0.024295387789607048035f, -0.36354508996009826660f, 0.53695374727249145508f, -0.060635715723037719727f, -0.30753347277641296387f, -0.53544646501541137695f}
};
static const float tensor__3_Constant_1_output_0[1] = 
{0.21334861218929290771f};
static const int64_t tensor__0_Reshape_1_output_0[4] = 
{0, 0, 0, 5};
union tensor_union_0 {
float tensor__0_Pad_output_0[1][8];
float tensor__2_Gemm_output_0[1][8];
float tensor__2_MatMul_output_0[1][8];
};
static union tensor_union_0 tu0;

union tensor_union_1 {
float tensor__1_Gemm_output_0[1][8];
float tensor__1_MatMul_output_0[1][8];
float tensor__2_activation_Relu_output_0[1][8];
float tensor__2_Sub_output_0[1][8];
};
static union tensor_union_1 tu1;

union tensor_union_2 {
float tensor__1_activation_Relu_output_0[1][8];
float tensor__1_Sub_output_0[1][8];
};
static union tensor_union_2 tu2;


static inline void node__0_Pad( const float data[1][3], const int64_t pads[4], const float constant_value[1], float output[1][8] )
{
	/* Pad: 
	 * pad at start: 0 0 
	 * pad at end:   0 5 
	 * mode: constant
	 */
	uint32_t ir0;
	for( uint32_t o0=0, il0=0; o0<1; o0++ ) {
		bool pad_at_0=false;
		if( o0 < 1){
			ir0=il0;
			il0++;
		}
		else {
			pad_at_0= true;
		}
		uint32_t ir1;
		for( uint32_t o1=0, il1=0; o1<8; o1++ ) {
			bool pad_at_1=false;
			if( o1 < 3){
				ir1=il1;
				il1++;
			}
			else {
				pad_at_1= true;
			}
	if ( pad_at_0  || pad_at_1)
		output[o0][o1] = 0.0000000000000000000;
	else
		output[o0][o1]= data[ir0][ir1];
		}
	}
}

static inline void node__1_Gemm( const float tensor__0_Pad_output_0[1][8], const float tensor__1_Constant_output_0[8][8], const float tensor__1_Constant_1_output_0[8], float tensor__1_Gemm_output_0[1][8] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 8;
	const int N = 8;
	float (*A)[8]  = (float(*)[8])tensor__0_Pad_output_0;
	float (*Y)[8]  = (float(*)[8])tensor__1_Gemm_output_0;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[8]  = (float(*)[8])tensor__1_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__1_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}

static inline void node__1_activation_Relu( const float tensor__1_Gemm_output_0[1][8], float tensor__1_activation_Relu_output_0[1][8] )
{
	/*Relu*/
	float *X = (float*)tensor__1_Gemm_output_0;
	float *Y = (float*)tensor__1_activation_Relu_output_0;
	for( uint32_t i=0; i<8; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;

}

static inline void node__1_MatMul( const float A[1][8], const float B[8][8], float Y[1][8] )
{
	/* MatMul */
	for( uint32_t r=0; r<1; r++ )
		for( uint32_t c=0; c<8; c++ ) {
			Y[r][c] = 0;
			for( uint32_t i=0; i<8; i++ )
				Y[r][c] += A[r][i] * B[i][c];
		}
}

static inline void node__1_Sub( const float tensor__0_Pad_output_0[1][8], const float tensor__1_MatMul_output_0[1][8], float tensor__1_Sub_output_0[1][8] )
{
	/* Sub
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<1; i0++) {
	for (unsigned i1=0; i1<8; i1++) {
		tensor__1_Sub_output_0[i0][i1] = tensor__0_Pad_output_0[0][i1]-tensor__1_MatMul_output_0[0][i1];;
	}
	}
}

static inline void node__2_Gemm( const float tensor__1_Sub_output_0[1][8], const float tensor__2_Constant_output_0[8][8], const float tensor__2_Constant_1_output_0[8], float tensor__2_Gemm_output_0[1][8] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 8;
	const int N = 8;
	float (*A)[8]  = (float(*)[8])tensor__1_Sub_output_0;
	float (*Y)[8]  = (float(*)[8])tensor__2_Gemm_output_0;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[8]  = (float(*)[8])tensor__2_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__2_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}

static inline void node__2_activation_Relu( const float tensor__2_Gemm_output_0[1][8], float tensor__2_activation_Relu_output_0[1][8] )
{
	/*Relu*/
	float *X = (float*)tensor__2_Gemm_output_0;
	float *Y = (float*)tensor__2_activation_Relu_output_0;
	for( uint32_t i=0; i<8; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;

}

static inline void node__2_MatMul( const float A[1][8], const float B[8][8], float Y[1][8] )
{
	/* MatMul */
	for( uint32_t r=0; r<1; r++ )
		for( uint32_t c=0; c<8; c++ ) {
			Y[r][c] = 0;
			for( uint32_t i=0; i<8; i++ )
				Y[r][c] += A[r][i] * B[i][c];
		}
}

static inline void node__2_Sub( const float tensor__1_Sub_output_0[1][8], const float tensor__2_MatMul_output_0[1][8], float tensor__2_Sub_output_0[1][8] )
{
	/* Sub
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<1; i0++) {
	for (unsigned i1=0; i1<8; i1++) {
		tensor__2_Sub_output_0[i0][i1] = tensor__1_Sub_output_0[0][i1]-tensor__2_MatMul_output_0[0][i1];;
	}
	}
}

static inline void node__3_Gemm( const float tensor__2_Sub_output_0[1][8], const float tensor__3_Constant_output_0[1][8], const float tensor__3_Constant_1_output_0[1], float tensor_43[1][1] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 8;
	const int N = 1;
	float (*A)[8]  = (float(*)[8])tensor__2_Sub_output_0;
	float (*Y)[1]  = (float(*)[1])tensor_43;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[1]  = (float(*)[1])tensor__3_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__3_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][0] * beta;
			Y[r][c] = tmp;
	}
}


void entry(const float tensor_onnx__Pad_0[1][3], float tensor_43[1][1]) {
	node__0_Pad( tensor_onnx__Pad_0, tensor__0_Reshape_1_output_0, tensor__0_Constant_8_output_0, tu0.tensor__0_Pad_output_0);
	node__1_Gemm( tu0.tensor__0_Pad_output_0, tensor__1_Constant_output_0, tensor__1_Constant_1_output_0, tu1.tensor__1_Gemm_output_0);
	node__1_activation_Relu( tu1.tensor__1_Gemm_output_0, tu2.tensor__1_activation_Relu_output_0);
	node__1_MatMul( tu2.tensor__1_activation_Relu_output_0, tensor__1_Constant_2_output_0, tu1.tensor__1_MatMul_output_0);
	node__1_Sub( tu0.tensor__0_Pad_output_0, tu1.tensor__1_MatMul_output_0, tu2.tensor__1_Sub_output_0);
	node__2_Gemm( tu2.tensor__1_Sub_output_0, tensor__2_Constant_output_0, tensor__2_Constant_1_output_0, tu0.tensor__2_Gemm_output_0);
	node__2_activation_Relu( tu0.tensor__2_Gemm_output_0, tu1.tensor__2_activation_Relu_output_0);
	node__2_MatMul( tu1.tensor__2_activation_Relu_output_0, tensor__2_Constant_2_output_0, tu0.tensor__2_MatMul_output_0);
	node__2_Sub( tu2.tensor__1_Sub_output_0, tu0.tensor__2_MatMul_output_0, tu1.tensor__2_Sub_output_0);
	node__3_Gemm( tu1.tensor__2_Sub_output_0, tensor__3_Constant_output_0, tensor__3_Constant_1_output_0, tensor_43);
}
