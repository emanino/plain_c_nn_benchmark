// This file is computer-generated by onnx2c 
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 2.0.1
// ONNX IR version: 14
// Model documentation: 
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
#define MAX(X,Y) ( X > Y ? X : Y)
#define MIN(X,Y) ( X < Y ? X : Y)
#define CLIP(X,L) ( MAX(MIN(X,L), -L) )

static const float tensor__0_Constant_8_output_0[1] = 
{0.0000000000000000000f};
static const float tensor__1_Constant_output_0[12][12] = 
{
  {-0.22627483308315277100f, -0.32376798987388610840f, -0.33836024999618530273f, 0.045693088322877883911f, 0.79617404937744140625f, 0.15444305539131164551f, -0.079917632043361663818f, 0.14118687808513641357f, 0.37714117765426635742f, -0.44956335425376892090f, -0.10401693731546401978f, 0.088009133934974670410f},
  {0.39528581500053405762f, -0.30122232437133789062f, 0.21792033314704895020f, -0.27838388085365295410f, 0.25282239913940429688f, -0.16535459458827972412f, 0.24722336232662200928f, 0.090092413127422332764f, -0.17640882730484008789f, 0.11890707910060882568f, -0.075514353811740875244f, 0.24474625289440155029f},
  {0.42509672045707702637f, 0.54239583015441894531f, -0.65278285741806030273f, 0.50493985414505004883f, 0.20457161962985992432f, -0.15589471161365509033f, 0.036007069051265716553f, -0.48283821344375610352f, 0.024357827380299568176f, 0.028416302055120468140f, -0.088100299239158630371f, -0.51401406526565551758f},
  {-0.29826128482818603516f, 0.33998188376426696777f, -0.14680936932563781738f, 0.39529636502265930176f, -0.030853299424052238464f, 0.34103795886039733887f, -0.10145464539527893066f, -0.31946033239364624023f, 0.061066199094057083130f, -0.066640935838222503662f, -0.021894311532378196716f, -0.82513755559921264648f},
  {-0.030152942985296249390f, 0.0072279507294297218323f, 0.088666476309299468994f, -0.15034525096416473389f, 0.046237640082836151123f, 0.0034591041039675474167f, -0.26625615358352661133f, 0.011282156221568584442f, 0.041899502277374267578f, 0.077912732958793640137f, 0.082173131406307220459f, -0.010183148086071014404f},
  {-0.28299340605735778809f, 0.066890329122543334961f, 0.043388426303863525391f, 0.097837820649147033691f, 0.30095377564430236816f, -0.34219634532928466797f, 0.13870616257190704346f, 0.33496895432472229004f, 0.042338997125625610352f, 0.55010372400283813477f, 0.011159555986523628235f, -0.17233024537563323975f},
  {0.25526648759841918945f, 0.32677394151687622070f, 0.12930464744567871094f, -0.0082833841443061828613f, 0.047457393258810043335f, -0.095983289182186126709f, -0.24590097367763519287f, 0.43039509654045104980f, -0.040707662701606750488f, -0.24253739416599273682f, -0.22632044553756713867f, -0.14119450747966766357f},
  {-0.20594927668571472168f, 0.29545590281486511230f, 0.077099531888961791992f, 0.38301083445549011230f, 0.21428789198398590088f, 0.023331651464104652405f, -0.018690053373575210571f, 0.18889640271663665771f, -0.12683431804180145264f, 0.30632382631301879883f, 0.19157315790653228760f, 0.22696943581104278564f},
  {-0.27772790193557739258f, 0.29243773221969604492f, -0.059851907193660736084f, -0.25542530417442321777f, 0.082022301852703094482f, 0.16097235679626464844f, -0.013317461125552654266f, -0.25716197490692138672f, -0.13558787107467651367f, 0.19590114057064056396f, -0.79152560234069824219f, 0.26893123984336853027f},
  {0.25981321930885314941f, 0.30945709347724914551f, 0.15311723947525024414f, -0.13068976998329162598f, -0.0078598195686936378479f, 0.42760387063026428223f, 0.24215009808540344238f, -0.020555108785629272461f, 0.54661685228347778320f, 0.061409395188093185425f, 0.10721850395202636719f, 0.13206152617931365967f},
  {0.33562248945236206055f, -0.38126003742218017578f, 0.38491126894950866699f, 0.27347490191459655762f, 0.15190103650093078613f, 0.095389164984226226807f, -0.076753415167331695557f, -0.14388647675514221191f, 0.035780359059572219849f, 0.18675047159194946289f, -0.29383173584938049316f, -0.12210008502006530762f},
  {-0.039627816528081893921f, 0.00071811379166319966316f, 0.22728843986988067627f, -0.069279059767723083496f, 0.098679736256599426270f, -0.35085737705230712891f, -0.0089989537373185157776f, -0.68925482034683227539f, 0.064766936004161834717f, -0.085977666079998016357f, 0.26939225196838378906f, 0.35536321997642517090f}
};
static const float tensor__1_Constant_1_output_0[12] = 
{0.40558424592018127441f, 0.34377738833427429199f, -0.39172580838203430176f, 1.5183026790618896484f, 0.56103545427322387695f, 0.54118871688842773438f, -0.72241991758346557617f, 1.0090923309326171875f, -0.15030482411384582520f, 0.47955983877182006836f, -0.17911604046821594238f, -0.013997978530824184418f};
static const float tensor__1_Constant_2_output_0[12][12] = 
{
  {-0.33691972494125366211f, -0.48208549618721008301f, -0.50381314754486083984f, 0.068036295473575592041f, 1.1854908466339111328f, 0.22996331751346588135f, -0.11899611353874206543f, 0.21022507548332214355f, 0.56155735254287719727f, -0.66939282417297363281f, -0.15487959980964660645f, 0.13104423880577087402f},
  {0.45198783278465270996f, -0.34443134069442749023f, 0.24918004870414733887f, -0.31831681728363037109f, 0.28908866643905639648f, -0.18907397985458374023f, 0.28268647193908691406f, 0.10301577299833297729f, -0.20171390473842620850f, 0.13596378266811370850f, -0.086346559226512908936f, 0.27985402941703796387f},
  {0.27208909392356872559f, 0.34716799855232238770f, -0.41782277822494506836f, 0.32319378852844238281f, 0.13093891739845275879f, -0.099782586097717285156f, 0.023046826943755149841f, -0.30904734134674072266f, 0.015590567141771316528f, 0.018188251182436943054f, -0.056389823555946350098f, -0.32900187373161315918f},
  {-0.079372383654117584229f, 0.090474940836429595947f, -0.039068460464477539062f, 0.10519506037235260010f, -0.0082105854526162147522f, 0.090755976736545562744f, -0.026998801156878471375f, -0.085013806819915771484f, 0.016250750049948692322f, -0.017734281718730926514f, -0.0058264471590518951416f, -0.21958309412002563477f},
  {-0.10784810781478881836f, 0.025852229446172714233f, 0.31713360548019409180f, -0.53774023056030273438f, 0.16537828743457794189f, 0.012372186407446861267f, -0.95231908559799194336f, 0.040352918207645416260f, 0.14986206591129302979f, 0.27867066860198974609f, 0.29390886425971984863f, -0.036422092467546463013f},
  {-0.35393348336219787598f, 0.083658225834369659424f, 0.054264925420284271240f, 0.12236355990171432495f, 0.37639611959457397461f, -0.42797726392745971680f, 0.17347666621208190918f, 0.41893813014030456543f, 0.052952431142330169678f, 0.68800234794616699219f, 0.013957004994153976440f, -0.21552956104278564453f},
  {0.74948734045028686523f, 0.95944017171859741211f, 0.37965106964111328125f, -0.024320824071764945984f, 0.13933953642845153809f, -0.28181630373001098633f, -0.72198927402496337891f, 1.2636820077896118164f, -0.11952167004346847534f, -0.71211344003677368164f, -0.66449892520904541016f, -0.41456085443496704102f},
  {-0.34081381559371948242f, 0.48893326520919799805f, 0.12758766114711761475f, 0.63382297754287719727f, 0.35461291670799255371f, 0.038610231131315231323f, -0.030929112806916236877f, 0.31259396672248840332f, -0.20989094674587249756f, 0.50691795349121093750f, 0.31702357530593872070f, 0.37559887766838073730f},
  {-0.50763469934463500977f, 0.53452152013778686523f, -0.10939809679985046387f, -0.46686971187591552734f, 0.14992143213748931885f, 0.29422736167907714844f, -0.024341829121112823486f, -0.47004401683807373047f, -0.24782927334308624268f, 0.35807067155838012695f, -1.4467607736587524414f, 0.49155601859092712402f},
  {0.57957911491394042969f, 0.69032233953475952148f, 0.34156674146652221680f, -0.29153659939765930176f, -0.017533315345644950867f, 0.95387858152389526367f, 0.54017704725265502930f, -0.045853368937969207764f, 1.2193671464920043945f, 0.13698919117450714111f, 0.23917798697948455811f, 0.29459664225578308105f},
  {0.80674880743026733398f, -0.91644954681396484375f, 0.92522615194320678711f, 0.65736222267150878906f, 0.36513039469718933105f, 0.22929063439369201660f, -0.18449515104293823242f, -0.34586548805236816406f, 0.086006633937358856201f, 0.44889932870864868164f, -0.70629471540451049805f, -0.29349669814109802246f},
  {-0.013806205242872238159f, 0.00025018854648806154728f, 0.079186566174030303955f, -0.024136602878570556641f, 0.034379705786705017090f, -0.12223759293556213379f, -0.0031352066434919834137f, -0.24013417959213256836f, 0.022564593702554702759f, -0.029954344034194946289f, 0.093855403363704681396f, 0.12380740791559219360f}
};
static const float tensor__2_Constant_output_0[12][12] = 
{
  {0.11076007783412933350f, 0.24513518810272216797f, 0.33294048905372619629f, 0.23458255827426910400f, -0.12309264391660690308f, -0.26058959960937500000f, -0.22978691756725311279f, -0.082542955875396728516f, -0.32651785016059875488f, 0.065982945263385772705f, 0.0010917440522462129593f, 0.10262612253427505493f},
  {0.30557397007942199707f, -0.38601592183113098145f, -0.43759381771087646484f, 0.37635043263435363770f, 0.54472762346267700195f, -0.13472229242324829102f, -0.34738591313362121582f, -0.14121934771537780762f, -0.21369060873985290527f, -0.42244845628738403320f, -0.080564528703689575195f, 0.17289109528064727783f},
  {-0.025472266599535942078f, -0.025007644668221473694f, -0.061577256768941879272f, 0.041533671319484710693f, -0.18450191617012023926f, -0.22748760879039764404f, -0.14143335819244384766f, 0.16117130219936370850f, 0.24434667825698852539f, -0.12832129001617431641f, 0.16985040903091430664f, 0.060863729566335678101f},
  {-0.066144280135631561279f, -0.14192217588424682617f, 0.029377041384577751160f, 0.22500291466712951660f, -0.0036740398500114679337f, 0.16112548112869262695f, 0.18431128561496734619f, -0.0082883955910801887512f, 0.19691966474056243896f, -0.062033802270889282227f, -0.021734997630119323730f, -0.027556212618947029114f},
  {-0.11420191824436187744f, -0.082384049892425537109f, -0.099574357271194458008f, 0.12405849993228912354f, -0.36006802320480346680f, -0.25806632637977600098f, 0.46409374475479125977f, 0.033967725932598114014f, -0.21333719789981842041f, -0.47930389642715454102f, -0.43910983204841613770f, -0.25490495562553405762f},
  {-0.16948525607585906982f, 0.27029097080230712891f, -0.46437975764274597168f, -0.12088175863027572632f, -0.17183104157447814941f, -0.49797478318214416504f, 0.51612257957458496094f, -0.17480018734931945801f, -0.11416595429182052612f, -0.26113304495811462402f, -0.43136397004127502441f, 0.055308263748884201050f},
  {0.10580593347549438477f, -0.12508848309516906738f, -0.0026731444522738456726f, 0.084820225834846496582f, -0.022187413647770881653f, -0.13601487874984741211f, 0.19345155358314514160f, 0.046108983457088470459f, -0.073542669415473937988f, 0.14813922345638275146f, 0.089809946715831756592f, 0.043853495270013809204f},
  {-0.19403797388076782227f, 0.13761688768863677979f, 0.15914282202720642090f, -0.24664798378944396973f, -0.034500852227210998535f, 0.15238431096076965332f, -0.38345888257026672363f, -0.13814362883567810059f, 0.066015556454658508301f, -0.47085234522819519043f, -0.27117779850959777832f, -0.25862103700637817383f},
  {0.037914600223302841187f, 0.076920472085475921631f, 0.40628734230995178223f, -0.26479551196098327637f, 0.25616526603698730469f, -0.17917786538600921631f, 0.062391247600317001343f, 0.11337845027446746826f, -0.061685711145401000977f, -0.19981862604618072510f, -0.0022762308362871408463f, 0.42127999663352966309f},
  {-0.11733520776033401489f, -0.14742977917194366455f, -0.030409896746277809143f, -0.059422552585601806641f, -0.18520042300224304199f, 0.092536933720111846924f, -0.020288240164518356323f, -0.17668004333972930908f, -0.11494279652833938599f, -0.043670035898685455322f, 0.099550396203994750977f, 0.19594232738018035889f},
  {-0.27036944031715393066f, -0.074679523706436157227f, -0.012883348390460014343f, -0.0059777540154755115509f, 0.29913145303726196289f, 0.28953155875205993652f, 0.33567136526107788086f, 0.19686700403690338135f, -0.049271624535322189331f, -0.38452363014221191406f, 0.64084541797637939453f, -0.30326145887374877930f},
  {-0.77990800142288208008f, -0.083818241953849792480f, 0.16551737487316131592f, 0.31736412644386291504f, 0.21941924095153808594f, -0.33033424615859985352f, -0.19502730667591094971f, 0.042271845042705535889f, -0.18541316688060760498f, 0.25158485770225524902f, -0.078888930380344390869f, -0.040038496255874633789f}
};
static const float tensor__2_Constant_1_output_0[12] = 
{0.19270308315753936768f, 0.20289894938468933105f, -0.44479525089263916016f, -0.21355971693992614746f, -0.32673928141593933105f, 0.53212970495223999023f, 0.092372491955757141113f, -0.013062532991170883179f, 0.25020739436149597168f, -0.74741280078887939453f, -0.81281948089599609375f, -0.24744126200675964355f};
static const float tensor__2_Constant_2_output_0[12][12] = 
{
  {0.039732821285724639893f, 0.087937027215957641602f, 0.11943531036376953125f, 0.084151498973369598389f, -0.044156864285469055176f, -0.093480966985225677490f, -0.082431167364120483398f, -0.029610527679324150085f, -0.11713132262229919434f, 0.023669976741075515747f, 0.00039163994370028376579f, 0.036814935505390167236f},
  {0.46582838892936706543f, -0.58845710754394531250f, -0.66708439588546752930f, 0.57372266054153442383f, 0.83040314912796020508f, -0.20537570118904113770f, -0.52956807613372802734f, -0.21528005599975585938f, -0.32575795054435729980f, -0.64399623870849609375f, -0.12281557917594909668f, 0.26356166601181030273f},
  {-0.20411667227745056152f, -0.20039351284503936768f, -0.49343645572662353516f, 0.33282136917114257812f, -1.4784674644470214844f, -1.8229242563247680664f, -1.1333465576171875000f, 1.2915124893188476562f, 1.9580209255218505859f, -1.0282757282257080078f, 1.3610606193542480469f, 0.48771873116493225098f},
  {-0.0063373805023729801178f, -0.013597771525382995605f, 0.0028146572876721620560f, 0.021557858213782310486f, -0.00035201513674110174179f, 0.015437668189406394958f, 0.017659133300185203552f, -0.00079412333434447646141f, 0.018867161124944686890f, -0.0059435493312776088715f, -0.0020824619568884372711f, -0.0026402010116726160049f},
  {-0.028056174516677856445f, -0.020239425823092460632f, -0.024462597444653511047f, 0.030477657914161682129f, -0.088458508253097534180f, -0.063399583101272583008f, 0.11401467770338058472f, 0.0083449073135852813721f, -0.052410904318094253540f, -0.11775138229131698608f, -0.10787684470415115356f, -0.062622927129268646240f},
  {-0.12436998635530471802f, 0.19834223389625549316f, -0.34076654911041259766f, -0.088704250752925872803f, -0.12609134614467620850f, -0.36541891098022460938f, 0.37873595952987670898f, -0.12827013432979583740f, -0.083776123821735382080f, -0.19162206351757049561f, -0.31653922796249389648f, 0.040585760027170181274f},
  {0.068995766341686248779f, -0.081569865345954895020f, -0.0017431504093110561371f, 0.055311042815446853638f, -0.014468353241682052612f, -0.088694937527179718018f, 0.12614923715591430664f, 0.030067546293139457703f, -0.047956980764865875244f, 0.096601195633411407471f, 0.058564826846122741699f, 0.028596747666597366333f},
  {-0.49847126007080078125f, 0.35352906584739685059f, 0.40882781147956848145f, -0.63362300395965576172f, -0.088630504906177520752f, 0.39146563410758972168f, -0.98508155345916748047f, -0.35488221049308776855f, 0.16958977282047271729f, -1.2095898389816284180f, -0.69663858413696289062f, -0.66438102722167968750f},
  {0.10945777595043182373f, 0.22206600010395050049f, 1.1729335784912109375f, -0.76445293426513671875f, 0.73953777551651000977f, -0.51727855205535888672f, 0.18012076616287231445f, 0.32731857895851135254f, -0.17808391153812408447f, -0.57686752080917358398f, -0.0065713776275515556335f, 1.2162166833877563477f},
  {-1.3144705295562744141f, -1.6516108512878417969f, -0.34067279100418090820f, -0.66569274663925170898f, -2.0747437477111816406f, 1.0366630554199218750f, -0.22728297114372253418f, -1.9792926311492919922f, -1.2876690626144409180f, -0.48922207951545715332f, 1.1152327060699462891f, 2.1950821876525878906f},
  {-0.48044651746749877930f, -0.13270552456378936768f, -0.022893710061907768250f, -0.010622469708323478699f, 0.53155660629272460938f, 0.51449757814407348633f, 0.59648805856704711914f, 0.34983268380165100098f, -0.087555676698684692383f, -0.68329852819442749023f, 1.1387823820114135742f, -0.53889560699462890625f},
  {-1.4578500986099243164f, -0.15667800605297088623f, 0.30939483642578125000f, 0.59323573112487792969f, 0.41015139222145080566f, -0.61748027801513671875f, -0.36455655097961425781f, 0.079017028212547302246f, -0.34658524394035339355f, 0.47027724981307983398f, -0.14746384322643280029f, -0.074842318892478942871f}
};
static const float tensor__3_Constant_output_0[1][12] = 
{
  {0.49198389053344726562f, -0.26243022084236145020f, 0.048084340989589691162f, -0.32902127504348754883f, -0.078036457300186157227f, 0.33276379108428955078f, -0.071456357836723327637f, -0.38962721824645996094f, -0.099701404571533203125f, -0.18452869355678558350f, -0.37667176127433776855f, 0.34482678771018981934f}
};
static const float tensor__3_Constant_1_output_0[1] = 
{-0.051957976073026657104f};
static const int64_t tensor__0_Reshape_1_output_0[4] = 
{0, 0, 0, 10};
union tensor_union_0 {
float tensor__0_Pad_output_0[1][12];
float tensor__2_Gemm_output_0[1][12];
float tensor__2_MatMul_output_0[1][12];
};
static union tensor_union_0 tu0;

union tensor_union_1 {
float tensor__1_Gemm_output_0[1][12];
float tensor__1_MatMul_output_0[1][12];
float tensor__2_activation_Relu_output_0[1][12];
float tensor__2_Sub_output_0[1][12];
};
static union tensor_union_1 tu1;

union tensor_union_2 {
float tensor__1_activation_Relu_output_0[1][12];
float tensor__1_Sub_output_0[1][12];
};
static union tensor_union_2 tu2;


static inline void node__0_Pad( const float data[1][2], const int64_t pads[4], const float constant_value[1], float output[1][12] )
{
	/* Pad: 
	 * pad at start: 0 0 
	 * pad at end:   0 10 
	 * mode: constant
	 */
	uint32_t ir0;
	for( uint32_t o0=0, il0=0; o0<1; o0++ ) {
		bool pad_at_0=false;
		if( o0 < 0){
			pad_at_0= true;
		}
		else if( o0 < 1){
			ir0=il0;
			il0++;
		}
		else {
			pad_at_0= true;
		}
		uint32_t ir1;
		for( uint32_t o1=0, il1=0; o1<12; o1++ ) {
			bool pad_at_1=false;
			if( o1 < 0){
				pad_at_1= true;
			}
			else if( o1 < 2){
				ir1=il1;
				il1++;
			}
			else {
				pad_at_1= true;
			}
	if ( pad_at_0  || pad_at_1)
		output[o0][o1] = 0.0000000000000000000;
	else
		output[o0][o1]= data[ir0][ir1];
		}
	}
}

static inline void node__1_Gemm( const float tensor__0_Pad_output_0[1][12], const float tensor__1_Constant_output_0[12][12], const float tensor__1_Constant_1_output_0[12], float tensor__1_Gemm_output_0[1][12] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 12;
	const int N = 12;
	float (*A)[12]  = (float(*)[12])tensor__0_Pad_output_0;
	float (*Y)[12]  = (float(*)[12])tensor__1_Gemm_output_0;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[12]  = (float(*)[12])tensor__1_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__1_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}

static inline void node__1_activation_Relu( const float tensor__1_Gemm_output_0[1][12], float tensor__1_activation_Relu_output_0[1][12] )
{
	/*Relu*/
	float *X = (float*)tensor__1_Gemm_output_0;
	float *Y = (float*)tensor__1_activation_Relu_output_0;
	for( uint32_t i=0; i<12; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;

}

static inline void node__1_MatMul( const float A[1][12], const float B[12][12], float Y[1][12] )
{
	/* MatMul */
	for( uint32_t r=0; r<1; r++ )
		for( uint32_t c=0; c<12; c++ ) {
			Y[r][c] = 0;
			for( uint32_t i=0; i<12; i++ )
				Y[r][c] += A[r][i] * B[i][c];
		}
}

static inline void node__1_Sub( const float tensor__0_Pad_output_0[1][12], const float tensor__1_MatMul_output_0[1][12], float tensor__1_Sub_output_0[1][12] )
{
	/* Sub
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<1; i0++) {
	for (unsigned i1=0; i1<12; i1++) {
		tensor__1_Sub_output_0[i0][i1] = tensor__0_Pad_output_0[0][i1]-tensor__1_MatMul_output_0[0][i1];;
	}
	}
}

static inline void node__2_Gemm( const float tensor__1_Sub_output_0[1][12], const float tensor__2_Constant_output_0[12][12], const float tensor__2_Constant_1_output_0[12], float tensor__2_Gemm_output_0[1][12] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 12;
	const int N = 12;
	float (*A)[12]  = (float(*)[12])tensor__1_Sub_output_0;
	float (*Y)[12]  = (float(*)[12])tensor__2_Gemm_output_0;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[12]  = (float(*)[12])tensor__2_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__2_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}

static inline void node__2_activation_Relu( const float tensor__2_Gemm_output_0[1][12], float tensor__2_activation_Relu_output_0[1][12] )
{
	/*Relu*/
	float *X = (float*)tensor__2_Gemm_output_0;
	float *Y = (float*)tensor__2_activation_Relu_output_0;
	for( uint32_t i=0; i<12; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;

}

static inline void node__2_MatMul( const float A[1][12], const float B[12][12], float Y[1][12] )
{
	/* MatMul */
	for( uint32_t r=0; r<1; r++ )
		for( uint32_t c=0; c<12; c++ ) {
			Y[r][c] = 0;
			for( uint32_t i=0; i<12; i++ )
				Y[r][c] += A[r][i] * B[i][c];
		}
}

static inline void node__2_Sub( const float tensor__1_Sub_output_0[1][12], const float tensor__2_MatMul_output_0[1][12], float tensor__2_Sub_output_0[1][12] )
{
	/* Sub
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<1; i0++) {
	for (unsigned i1=0; i1<12; i1++) {
		tensor__2_Sub_output_0[i0][i1] = tensor__1_Sub_output_0[0][i1]-tensor__2_MatMul_output_0[0][i1];;
	}
	}
}

static inline void node__3_Gemm( const float tensor__2_Sub_output_0[1][12], const float tensor__3_Constant_output_0[1][12], const float tensor__3_Constant_1_output_0[1], float tensor_43[1][1] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 12;
	const int N = 1;
	float (*A)[12]  = (float(*)[12])tensor__2_Sub_output_0;
	float (*Y)[1]  = (float(*)[1])tensor_43;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[1]  = (float(*)[1])tensor__3_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__3_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][0] * beta;
			Y[r][c] = tmp;
	}
}


void entry(const float tensor_onnx__Pad_0[1][2], float tensor_43[1][1]) {
	node__0_Pad( tensor_onnx__Pad_0, tensor__0_Reshape_1_output_0, tensor__0_Constant_8_output_0, tu0.tensor__0_Pad_output_0);
	node__1_Gemm( tu0.tensor__0_Pad_output_0, tensor__1_Constant_output_0, tensor__1_Constant_1_output_0, tu1.tensor__1_Gemm_output_0);
	node__1_activation_Relu( tu1.tensor__1_Gemm_output_0, tu2.tensor__1_activation_Relu_output_0);
	node__1_MatMul( tu2.tensor__1_activation_Relu_output_0, tensor__1_Constant_2_output_0, tu1.tensor__1_MatMul_output_0);
	node__1_Sub( tu0.tensor__0_Pad_output_0, tu1.tensor__1_MatMul_output_0, tu2.tensor__1_Sub_output_0);
	node__2_Gemm( tu2.tensor__1_Sub_output_0, tensor__2_Constant_output_0, tensor__2_Constant_1_output_0, tu0.tensor__2_Gemm_output_0);
	node__2_activation_Relu( tu0.tensor__2_Gemm_output_0, tu1.tensor__2_activation_Relu_output_0);
	node__2_MatMul( tu1.tensor__2_activation_Relu_output_0, tensor__2_Constant_2_output_0, tu0.tensor__2_MatMul_output_0);
	node__2_Sub( tu2.tensor__1_Sub_output_0, tu0.tensor__2_MatMul_output_0, tu1.tensor__2_Sub_output_0);
	node__3_Gemm( tu1.tensor__2_Sub_output_0, tensor__3_Constant_output_0, tensor__3_Constant_1_output_0, tensor_43);
}
