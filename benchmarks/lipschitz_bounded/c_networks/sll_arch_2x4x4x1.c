// This file is computer-generated by onnx2c 
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 2.0.1
// ONNX IR version: 14
// Model documentation: 
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
#define MAX(X,Y) ( X > Y ? X : Y)
#define MIN(X,Y) ( X < Y ? X : Y)
#define CLIP(X,L) ( MAX(MIN(X,L), -L) )

static const float tensor__0_Constant_8_output_0[1] = 
{0.0000000000000000000f};
static const float tensor__1_Constant_output_0[4][4] = 
{
  {0.50001579523086547852f, 0.48913460969924926758f, 0.037512548267841339111f, 0.41833165287971496582f},
  {0.44111785292625427246f, -0.45883423089981079102f, -0.42495897412300109863f, 0.046170547604560852051f},
  {-0.30884140729904174805f, 0.49573934078216552734f, 0.23029871284961700439f, -0.26539334654808044434f},
  {0.23099391162395477295f, -0.15732261538505554199f, 0.38533088564872741699f, -0.22932469844818115234f}
};
static const float tensor__1_Constant_1_output_0[4] = 
{0.42912372946739196777f, -0.036163330078125000000f, -1.2611292600631713867f, -0.65015524625778198242f};
static const float tensor__1_Constant_2_output_0[4][4] = 
{
  {1.3067048788070678711f, 1.2782688140869140625f, 0.098032563924789428711f, 1.0932375192642211914f},
  {0.98116260766983032227f, -1.0205684900283813477f, -0.94522100687026977539f, 0.10269549489021301270f},
  {-0.50703531503677368164f, 0.81387197971343994141f, 0.37808915972709655762f, -0.43570518493652343750f},
  {1.5431889295578002930f, -1.0510170459747314453f, 2.5742599964141845703f, -1.5320374965667724609f}
};
static const float tensor__2_Constant_output_0[4][4] = 
{
  {0.086487345397472381592f, -0.081025823950767517090f, -0.22616218030452728271f, -0.032926425337791442871f},
  {0.38314473628997802734f, -0.18515300750732421875f, 0.19779938459396362305f, -0.11301700770854949951f},
  {0.21521832048892974854f, 0.21532604098320007324f, 0.028954671695828437805f, 0.42958959937095642090f},
  {0.37259474396705627441f, 0.35111126303672790527f, -0.10049360990524291992f, -0.35901519656181335449f}
};
static const float tensor__2_Constant_1_output_0[4] = 
{0.033749379217624664307f, 0.37263458967208862305f, 0.97758841514587402344f, 0.68921816349029541016f};
static const float tensor__2_Constant_2_output_0[4][4] = 
{
  {0.57767575979232788086f, -0.54119658470153808594f, -1.5106072425842285156f, -0.21992579102516174316f},
  {1.1920167207717895508f, -0.57603687047958374023f, 0.61538147926330566406f, -0.35161167383193969727f},
  {1.5255651473999023438f, 1.5263286828994750977f, 0.20524385571479797363f, 3.0451259613037109375f},
  {1.6901967525482177734f, 1.5927416086196899414f, -0.45586788654327392578f, -1.6285960674285888672f}
};
static const float tensor__3_Constant_output_0[1][4] = 
{
  {0.36783438920974731445f, -0.26806315779685974121f, -0.75471824407577514648f, -0.47248321771621704102f}
};
static const float tensor__3_Constant_1_output_0[1] = 
{0.37493458390235900879f};
static const int64_t tensor__0_Reshape_1_output_0[4] = 
{0, 0, 0, 2};
union tensor_union_0 {
float tensor__0_Pad_output_0[1][4];
float tensor__2_Gemm_output_0[1][4];
float tensor__2_MatMul_output_0[1][4];
};
static union tensor_union_0 tu0;

union tensor_union_1 {
float tensor__1_Gemm_output_0[1][4];
float tensor__1_MatMul_output_0[1][4];
float tensor__2_activation_Relu_output_0[1][4];
float tensor__2_Sub_output_0[1][4];
};
static union tensor_union_1 tu1;

union tensor_union_2 {
float tensor__1_activation_Relu_output_0[1][4];
float tensor__1_Sub_output_0[1][4];
};
static union tensor_union_2 tu2;


static inline void node__0_Pad( const float data[1][2], const int64_t pads[4], const float constant_value[1], float output[1][4] )
{
	/* Pad: 
	 * pad at start: 0 0 
	 * pad at end:   0 2 
	 * mode: constant
	 */
	uint32_t ir0;
	for( uint32_t o0=0, il0=0; o0<1; o0++ ) {
		bool pad_at_0=false;
		if( o0 < 0){
			pad_at_0= true;
		}
		else if( o0 < 1){
			ir0=il0;
			il0++;
		}
		else {
			pad_at_0= true;
		}
		uint32_t ir1;
		for( uint32_t o1=0, il1=0; o1<4; o1++ ) {
			bool pad_at_1=false;
			if( o1 < 0){
				pad_at_1= true;
			}
			else if( o1 < 2){
				ir1=il1;
				il1++;
			}
			else {
				pad_at_1= true;
			}
	if ( pad_at_0  || pad_at_1)
		output[o0][o1] = 0.0000000000000000000;
	else
		output[o0][o1]= data[ir0][ir1];
		}
	}
}

static inline void node__1_Gemm( const float tensor__0_Pad_output_0[1][4], const float tensor__1_Constant_output_0[4][4], const float tensor__1_Constant_1_output_0[4], float tensor__1_Gemm_output_0[1][4] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 4;
	const int N = 4;
	float (*A)[4]  = (float(*)[4])tensor__0_Pad_output_0;
	float (*Y)[4]  = (float(*)[4])tensor__1_Gemm_output_0;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[4]  = (float(*)[4])tensor__1_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__1_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}

static inline void node__1_activation_Relu( const float tensor__1_Gemm_output_0[1][4], float tensor__1_activation_Relu_output_0[1][4] )
{
	/*Relu*/
	float *X = (float*)tensor__1_Gemm_output_0;
	float *Y = (float*)tensor__1_activation_Relu_output_0;
	for( uint32_t i=0; i<4; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;

}

static inline void node__1_MatMul( const float A[1][4], const float B[4][4], float Y[1][4] )
{
	/* MatMul */
	for( uint32_t r=0; r<1; r++ )
		for( uint32_t c=0; c<4; c++ ) {
			Y[r][c] = 0;
			for( uint32_t i=0; i<4; i++ )
				Y[r][c] += A[r][i] * B[i][c];
		}
}

static inline void node__1_Sub( const float tensor__0_Pad_output_0[1][4], const float tensor__1_MatMul_output_0[1][4], float tensor__1_Sub_output_0[1][4] )
{
	/* Sub
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<1; i0++) {
	for (unsigned i1=0; i1<4; i1++) {
		tensor__1_Sub_output_0[i0][i1] = tensor__0_Pad_output_0[0][i1]-tensor__1_MatMul_output_0[0][i1];;
	}
	}
}

static inline void node__2_Gemm( const float tensor__1_Sub_output_0[1][4], const float tensor__2_Constant_output_0[4][4], const float tensor__2_Constant_1_output_0[4], float tensor__2_Gemm_output_0[1][4] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 4;
	const int N = 4;
	float (*A)[4]  = (float(*)[4])tensor__1_Sub_output_0;
	float (*Y)[4]  = (float(*)[4])tensor__2_Gemm_output_0;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[4]  = (float(*)[4])tensor__2_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__2_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}

static inline void node__2_activation_Relu( const float tensor__2_Gemm_output_0[1][4], float tensor__2_activation_Relu_output_0[1][4] )
{
	/*Relu*/
	float *X = (float*)tensor__2_Gemm_output_0;
	float *Y = (float*)tensor__2_activation_Relu_output_0;
	for( uint32_t i=0; i<4; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;

}

static inline void node__2_MatMul( const float A[1][4], const float B[4][4], float Y[1][4] )
{
	/* MatMul */
	for( uint32_t r=0; r<1; r++ )
		for( uint32_t c=0; c<4; c++ ) {
			Y[r][c] = 0;
			for( uint32_t i=0; i<4; i++ )
				Y[r][c] += A[r][i] * B[i][c];
		}
}

static inline void node__2_Sub( const float tensor__1_Sub_output_0[1][4], const float tensor__2_MatMul_output_0[1][4], float tensor__2_Sub_output_0[1][4] )
{
	/* Sub
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<1; i0++) {
	for (unsigned i1=0; i1<4; i1++) {
		tensor__2_Sub_output_0[i0][i1] = tensor__1_Sub_output_0[0][i1]-tensor__2_MatMul_output_0[0][i1];;
	}
	}
}

static inline void node__3_Gemm( const float tensor__2_Sub_output_0[1][4], const float tensor__3_Constant_output_0[1][4], const float tensor__3_Constant_1_output_0[1], float tensor_43[1][1] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 4;
	const int N = 1;
	float (*A)[4]  = (float(*)[4])tensor__2_Sub_output_0;
	float (*Y)[1]  = (float(*)[1])tensor_43;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[1]  = (float(*)[1])tensor__3_Constant_1_output_0;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor__3_Constant_output_0[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][0] * beta;
			Y[r][c] = tmp;
	}
}


void entry(const float tensor_onnx__Pad_0[1][2], float tensor_43[1][1]) {
	node__0_Pad( tensor_onnx__Pad_0, tensor__0_Reshape_1_output_0, tensor__0_Constant_8_output_0, tu0.tensor__0_Pad_output_0);
	node__1_Gemm( tu0.tensor__0_Pad_output_0, tensor__1_Constant_output_0, tensor__1_Constant_1_output_0, tu1.tensor__1_Gemm_output_0);
	node__1_activation_Relu( tu1.tensor__1_Gemm_output_0, tu2.tensor__1_activation_Relu_output_0);
	node__1_MatMul( tu2.tensor__1_activation_Relu_output_0, tensor__1_Constant_2_output_0, tu1.tensor__1_MatMul_output_0);
	node__1_Sub( tu0.tensor__0_Pad_output_0, tu1.tensor__1_MatMul_output_0, tu2.tensor__1_Sub_output_0);
	node__2_Gemm( tu2.tensor__1_Sub_output_0, tensor__2_Constant_output_0, tensor__2_Constant_1_output_0, tu0.tensor__2_Gemm_output_0);
	node__2_activation_Relu( tu0.tensor__2_Gemm_output_0, tu1.tensor__2_activation_Relu_output_0);
	node__2_MatMul( tu1.tensor__2_activation_Relu_output_0, tensor__2_Constant_2_output_0, tu0.tensor__2_MatMul_output_0);
	node__2_Sub( tu2.tensor__1_Sub_output_0, tu0.tensor__2_MatMul_output_0, tu1.tensor__2_Sub_output_0);
	node__3_Gemm( tu1.tensor__2_Sub_output_0, tensor__3_Constant_output_0, tensor__3_Constant_1_output_0, tensor_43);
}
